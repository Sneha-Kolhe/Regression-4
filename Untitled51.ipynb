{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab28d0f-24fc-4b76-9df2-079301f10b78",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622c317-0392-460d-aeed-dfee003d0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso Regression, short for Least Absolute Shrinkage and Selection Operator Regression, is a regularization technique used in linear regression models. It is similar to Ridge Regression but differs in the type of penalty applied to the regression coefficients. Lasso Regression introduces an L1 regularization term, which encourages sparsity in the coefficient estimates by penalizing the absolute values of the coefficients.\n",
    "\n",
    "Here's an explanation of Lasso Regression and how it differs from other regression techniques:\n",
    "\n",
    "Lasso Regression:\n",
    "\n",
    "Lasso Regression extends ordinary least squares (OLS) regression by adding a penalty term to the cost function, known as the L1 regularization term.\n",
    "The Lasso regression objective function is given by:\n",
    "Cost function\n",
    "=\n",
    "RSS\n",
    "+\n",
    "�\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "∣\n",
    "�\n",
    "�\n",
    "∣\n",
    "Cost function=RSS+λ∑ \n",
    "j=1\n",
    "p\n",
    "​\n",
    " ∣β \n",
    "j\n",
    "​\n",
    " ∣\n",
    "Where:\n",
    "RSS\n",
    "RSS is the residual sum of squares.\n",
    "�\n",
    "λ (lambda) is the regularization parameter, which controls the strength of the penalty term.\n",
    "�\n",
    "�\n",
    "β \n",
    "j\n",
    "​\n",
    "  are the regression coefficients.\n",
    "�\n",
    "p is the number of predictors (independent variables).\n",
    "Unlike Ridge Regression, which penalizes the squared values of coefficients, Lasso Regression penalizes the absolute values of coefficients. As a result, Lasso tends to shrink some coefficients to exactly zero, effectively performing variable selection by eliminating irrelevant predictors from the model.\n",
    "Lasso Regression is particularly useful when dealing with high-dimensional datasets with many predictors, as it can automatically select a subset of the most relevant predictors and discard the rest.\n",
    "Differences from Ridge Regression:\n",
    "\n",
    "The key difference between Lasso Regression and Ridge Regression lies in the type of penalty applied to the regression coefficients. Lasso uses an L1 penalty, while Ridge uses an L2 penalty.\n",
    "Lasso Regression tends to produce sparse coefficient estimates by shrinking some coefficients to zero, effectively performing variable selection. In contrast, Ridge Regression typically shrinks all coefficients towards zero but rarely sets any coefficients exactly to zero.\n",
    "As a result of its variable selection property, Lasso Regression is often preferred when there is a need to identify the most important predictors in the model or when dealing with high-dimensional datasets with many irrelevant predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfc53b-81d8-4161-ae09-89be6bed097d",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d2222-aafb-40c9-ac8f-1cbae0b48184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
